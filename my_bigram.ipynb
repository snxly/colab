{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMr7DerAUfRPksw2ITCSv0s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snxly/colab/blob/master/my_bigram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV6-TMDghjOi",
        "outputId": "58e44c5d-f2ac-40df-87df-f4f3f83b9de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-03 02:09:38--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt.2’\n",
            "\n",
            "names.txt.2         100%[===================>] 222.80K  1.36MB/s    in 0.2s    \n",
            "\n",
            "2025-08-03 02:09:38 (1.36 MB/s) - ‘names.txt.2’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get file\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "# size of words\n",
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC3YqzEOhrIA",
        "outputId": "f7adbd73-4f8d-435e-d248-16486738f89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I need utils i2s and s2i\n",
        "chs = sorted(list(set(\"\".join(words))))\n",
        "s2i = {s:i+1 for i,s in enumerate(chs)}\n",
        "s2i['.'] = 0\n",
        "i2s = {i:s for s,i in s2i.items()}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xg46-KMXiSnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model by counting"
      ],
      "metadata": {
        "id": "mB61lEFikQCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init a tensor to save the count\n",
        "import torch\n",
        "vocab_size = len(s2i)\n",
        "counts = torch.zeros((vocab_size, vocab_size), dtype=torch.int32)\n",
        "counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPeqo9GOjJBY",
        "outputId": "67c1119c-0222-405d-fe4f-7d42c9ad14aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get demo tuple\n",
        "for w in words:\n",
        "  chs = '.' + w + '.'\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    counts[s2i[ch1], s2i[ch2]] += 1\n",
        "\n",
        "# counts"
      ],
      "metadata": {
        "id": "r7H_zEhqh03q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize counts\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(counts, cmap='Blues')\n",
        "for i in range(vocab_size):\n",
        "    for j in range(vocab_size):\n",
        "        chstr = i2s[i] + i2s[j]\n",
        "        plt.text(j, i, chstr, ha=\"center\", va=\"top\", color='gray')\n",
        "        plt.text(j, i, counts[i, j].item(), ha=\"center\", va=\"bottom\", color='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sa61e-J5jqfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample\n"
      ],
      "metadata": {
        "id": "pmZxYG0ckZm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. turn counts to probs\n",
        "probs = (counts+1).float()\n",
        "probs /= probs.sum(1, keepdim=True)\n",
        "probs[0], probs[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "042ka063kfEJ",
        "outputId": "46d274e1-89a7-435e-b646-65060c4cbc0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3.1192e-05, 1.3759e-01, 4.0767e-02, 4.8129e-02, 5.2745e-02, 4.7785e-02,\n",
              "         1.3038e-02, 2.0898e-02, 2.7293e-02, 1.8465e-02, 7.5577e-02, 9.2452e-02,\n",
              "         4.9064e-02, 7.9195e-02, 3.5777e-02, 1.2321e-02, 1.6095e-02, 2.9008e-03,\n",
              "         5.1154e-02, 6.4130e-02, 4.0830e-02, 2.4641e-03, 1.1759e-02, 9.6070e-03,\n",
              "         4.2109e-03, 1.6719e-02, 2.9008e-02]),\n",
              " tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. sample with the probs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "for i in range(5):\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    p = probs[ix]\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(i2s[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1shtmyQ0k3Tb",
        "outputId": "8b61ac5e-b312-41b2-8b09-f8a7983a7c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "janasah.\n",
            "p.\n",
            "cony.\n",
            "a.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate\n"
      ],
      "metadata": {
        "id": "5GNcRw8hl1ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from probs to negative log likelihood\n",
        "n = 0\n",
        "total = 0\n",
        "for w in words:\n",
        "  chs = '.' + w + '.'\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    prob = probs[s2i[ch1], s2i[ch2]]\n",
        "    total += -torch.log(prob)\n",
        "    n += 1\n",
        "nll = total/n\n",
        "nll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ShOK0fbl3iu",
        "outputId": "261fa90c-14d4-4a2a-f7d2-6544ad33fc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.4544)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model by ML"
      ],
      "metadata": {
        "id": "x0lPxYYXwH3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. setup training set\n",
        "xs, ys = [], []\n",
        "for w in words[:1]:\n",
        "  chs = '.' + w + '.'\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = s2i[ch1]\n",
        "    ix2 = s2i[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)\n",
        "print(xs, ys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1Kpn69UwihT",
        "outputId": "c0f72545-c1ff-4a8e-d1f6-6bea43ef4c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of examples:  5\n",
            "tensor([ 0,  5, 13, 13,  1]) tensor([ 5, 13, 13,  1,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. init weights\n",
        "W = torch.randn((vocab_size, vocab_size), requires_grad=True)\n",
        "# 3. encode x\n",
        "import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes=vocab_size).float()\n",
        "plt.imshow(xenc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "2H3xXe5nw3Ii",
        "outputId": "c9eaf249-d109-4b30-81c9-435774f98011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x785e29f77810>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "logits = xenc @ W\n",
        "# loss\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "loss = -probs[torch.arange(num), ys].log().mean()\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBDvg9dGxeIz",
        "outputId": "013983bd-8af8-481e-ffe4-3287a32b7333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.4108, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backward pass\n",
        "W.grad = None\n",
        "loss.backward()\n",
        "# update data\n",
        "W.data += -0.1 * W.grad"
      ],
      "metadata": {
        "id": "NcI6ohB8x2L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "1. setup training data\n",
        "2. init weights"
      ],
      "metadata": {
        "id": "eCyy3b7zzSLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all in one\n",
        "# 1. setup training set\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = '.' + w + '.'\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = s2i[ch1]\n",
        "    ix2 = s2i[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "# 2. init weights\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((vocab_size, vocab_size), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "qg1CYtfPyEJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "VzR9zvXQzcx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):\n",
        "  # encode input to one-hot\n",
        "  xenc = F.one_hot(xs, num_classes=vocab_size).float()\n",
        "  # forward pass\n",
        "  logits = xenc @ W\n",
        "  # loss = average negative log likelihood\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.0\n",
        "  print('loss = ', loss)\n",
        "  # backward pass\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "  # update data\n",
        "  W.data += -1 * W.grad"
      ],
      "metadata": {
        "id": "qhabIfl-zf95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample"
      ],
      "metadata": {
        "id": "Mc1rudUB0RUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  out = []\n",
        "  idx = 0\n",
        "  while True:\n",
        "    # get probs with forward pass\n",
        "    xenc = F.one_hot(torch.tensor([idx]), num_classes=vocab_size).float()\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdims=True)\n",
        "    idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(i2s[idx])\n",
        "    if idx == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TChV773k0Uvg",
        "outputId": "6aa5e2e0-e93f-4f5e-9927-bb5daeaba892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "morvann.\n",
            "akela.\n",
            "az.\n",
            "arileri.\n",
            "chaiadayrausbalodouseyton.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 教训\n",
        "1. 变量名不要和预留名字重复，比如 len\n",
        "2. 第一次nll算出来了两倍的值，原因是统计了二维数组里的所有概率，导致每个概率都统计了两遍。正确的做法是，统计每一种可能的两位字符的概率。"
      ],
      "metadata": {
        "id": "7bvlFgrfuom6"
      }
    }
  ]
}